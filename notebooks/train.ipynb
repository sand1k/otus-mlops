{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6503362c-e962-47c4-896f-917c13d7e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() \n",
    "\n",
    "from datetime import datetime\n",
    "import pyspark\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12ea58c-9433-44d9-bb98-9a25220be5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_pipeline():\n",
    "    # Define the pipeline stages\n",
    "    stages = []\n",
    "\n",
    "    # Define numerical columns and apply StandardScaler\n",
    "    numerical_columns = [\n",
    "         \"tx_amount\",\n",
    "         \"is_weekend\",\n",
    "         \"is_night\",\n",
    "         \"customer_id_nb_tx_1day_window\",\n",
    "         \"customer_id_avg_amount_1day_window\",\n",
    "         \"customer_id_nb_tx_7day_window\",\n",
    "         \"customer_id_avg_amount_7day_window\",\n",
    "         \"customer_id_nb_tx_30day_window\",\n",
    "         \"customer_id_avg_amount_30day_window\",\n",
    "         \"terminal_id_nb_tx_1day_window\",\n",
    "         \"terminal_id_risk_1day_window\",\n",
    "         \"terminal_id_nb_tx_7day_window\",\n",
    "         \"terminal_id_risk_7day_window\",\n",
    "         \"terminal_id_nb_tx_30day_window\",\n",
    "         \"terminal_id_risk_30day_window\"\n",
    "    ]\n",
    "    \n",
    "    assembler_input = [column for column in numerical_columns] \n",
    "    vector_assembler = VectorAssembler(inputCols=assembler_input, outputCol=\"features\")\n",
    "    stages += [vector_assembler]\n",
    "    \n",
    "    # Add model\n",
    "    #classification = RandomForestClassifier(featuresCol='features', labelCol='tx_fraud')\n",
    "    classification = LogisticRegression(featuresCol='features', labelCol='tx_fraud')\n",
    "    stages += [classification]\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def calculate_accuracy(predictions):\n",
    "    predictions = predictions.withColumn(\n",
    "        \"fraudPrediction\",\n",
    "        when((predictions.tx_fraud==1) & (predictions.prediction==1), 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "    accurateFraud = predictions.groupBy(\"fraudPrediction\").count().where(predictions.fraudPrediction==1).head()[1]\n",
    "    totalFraud = predictions.groupBy(\"tx_fraud\").count().where(predictions.tx_fraud==1).head()[1]\n",
    "    accuracy = (accurateFraud/totalFraud)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df605ead-bb9b-4222-acce-f32613e5e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new model / inference pipeline ...\n",
      "Scoring the model ...\n",
      "Logging metrics to MLflow run b12c7fb16308485d875eb11783215f97 ...\n",
      "Model ROC-train: 0.8141330876853555\n",
      "Model ROC-test: 0.8721979463746867\n",
      "Saving model locally...\n",
      "FraudPredictionAccuracy train: 63.2311616585584\n",
      "FraudPredictionAccuracy test: 74.98240709041805\n",
      "Exporting/logging model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'fraud_classifier' already exists. Creating a new version of this model...\n",
      "2023/06/20 13:27:24 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fraud_classifier, version 17\n",
      "Created version '17' of model 'fraud_classifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = (\n",
    "        pyspark.sql.SparkSession.builder\n",
    "            #.config('spark.executor.instances', 8)\n",
    "            .config(\"spark.executor.cores\", 4)\n",
    "            .appName(\"fraud_data_train\")\n",
    "            .getOrCreate()\n",
    "    )\n",
    "    spark.conf.set('spark.sql.repl.eagerEval.enabled', True)  # to pretty print pyspark.DataFrame in jupyter\n",
    "    \n",
    "    df = spark.read.parquet(\"/user/transformed_full/\")\n",
    "    df_train = df.filter(col('ts').between(\"2019-09-21\", \"2019-10-13\"))\n",
    "    df_test = df.filter(col('ts').between(\"2019-10-21\", \"2019-10-27\"))\n",
    "\n",
    "    client = MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(\"Fraud_Data\")\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "    run_name = 'Fraud_data_pipeline' + ' ' + str(datetime.now())\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, experiment_id=experiment_id):\n",
    "        # Train model\n",
    "        print(\"Fitting new model / inference pipeline ...\")\n",
    "\n",
    "        pipeline = build_train_pipeline()\n",
    "        model = pipeline.fit(df_train)\n",
    "\n",
    "        print(\"Scoring the model ...\")\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol='tx_fraud', rawPredictionCol='prediction')\n",
    "\n",
    "        predictions_train = model.transform(df_train)\n",
    "        predictions_train.head()\n",
    "        areaUnderROC_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "        predictions_test = model.transform(df_test)\n",
    "        areaUnderROC_test = evaluator.evaluate(predictions_test)\n",
    "\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"Logging metrics to MLflow run {run_id} ...\")\n",
    "        mlflow.log_metric(\"ROC-train\", areaUnderROC_train)\n",
    "        print(f\"Model ROC-train: {areaUnderROC_train}\")\n",
    "        mlflow.log_metric(\"ROC-test\", areaUnderROC_test)\n",
    "        print(f\"Model ROC-test: {areaUnderROC_test}\")\n",
    "\n",
    "        print(\"Saving model locally...\")\n",
    "        model.write().overwrite().save(\"/user/models/latest.mdl\")\n",
    "\n",
    "        FraudPredictionAccuracy = calculate_accuracy(predictions_train)\n",
    "        print(\"FraudPredictionAccuracy train:\", FraudPredictionAccuracy)\n",
    "        FraudPredictionAccuracy = calculate_accuracy(predictions_test)\n",
    "        print(\"FraudPredictionAccuracy test:\", FraudPredictionAccuracy)\n",
    "\n",
    "        print(\"Exporting/logging model ...\")\n",
    "        mlflow.spark.log_model(model, 'fraud_classifier', registered_model_name='fraud_classifier')\n",
    "        print(\"Done\")\n",
    "    \n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
